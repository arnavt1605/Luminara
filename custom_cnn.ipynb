{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2927490,"sourceType":"datasetVersion","datasetId":1794588}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os,joblib,random\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\naccuracy_score, precision_score, recall_score,\nf1_score, roc_auc_score, average_precision_score\n)\n\ndevice= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:22.753205Z","iopub.execute_input":"2025-08-24T05:18:22.753746Z","iopub.status.idle":"2025-08-24T05:18:22.758174Z","shell.execute_reply.started":"2025-08-24T05:18:22.753723Z","shell.execute_reply":"2025-08-24T05:18:22.757562Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"path= \"/kaggle/input/exotraincsv/exoTrain.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:22.759301Z","iopub.execute_input":"2025-08-24T05:18:22.759516Z","iopub.status.idle":"2025-08-24T05:18:22.769285Z","shell.execute_reply.started":"2025-08-24T05:18:22.759500Z","shell.execute_reply":"2025-08-24T05:18:22.768677Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class Exodata(Dataset):\n    def __init__(self,x,y):\n        self.x= x.astype(np.float32)\n        self.y= y.astype(np.float32)\n    def __len__(self):\n        return len(self.y)\n    def __getitem__(self, idx):\n        x= self.x[idx]\n        x = torch.from_numpy(x)[None, :]\n        y = torch.tensor(self.y[idx], dtype=torch.float32)\n        return x, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:22.770395Z","iopub.execute_input":"2025-08-24T05:18:22.770867Z","iopub.status.idle":"2025-08-24T05:18:22.778578Z","shell.execute_reply.started":"2025-08-24T05:18:22.770841Z","shell.execute_reply":"2025-08-24T05:18:22.777939Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, input_length):\n        super().__init__()\n        self.stack= nn.Sequential(\n            nn.Conv1d(1, 32, kernel_size=11, padding=5),\n            nn.BatchNorm1d(32),\n            nn.ReLU(),\n            nn.MaxPool1d(2),\n            \n            nn.Conv1d(32, 64, kernel_size=9, padding=4),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.MaxPool1d(2),\n            \n            nn.Conv1d(64, 128, kernel_size=7, padding=3),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool1d(1)\n        )\n\n        self.classifier=  nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.4),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, x):\n        x=self.stack(x)\n        x= self.classifier(x).squeeze(1)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:22.779322Z","iopub.execute_input":"2025-08-24T05:18:22.779561Z","iopub.status.idle":"2025-08-24T05:18:22.790999Z","shell.execute_reply.started":"2025-08-24T05:18:22.779540Z","shell.execute_reply":"2025-08-24T05:18:22.790346Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1.0, gamma=2.0, reduction='mean'):\n        super().__init__()\n        self.alpha= alpha\n        self.gamma= gamma\n        self.reduction= reduction\n\n    def forward(self, logits, targets):\n        bce= nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n        p= torch.sigmoid(logits)\n        pt=torch.where(targets == 1, p, 1-p)\n        loss= self.alpha*(1-pt)**self.gamma * bce\n\n        if self.reduction == \"mean\":\n            return loss.mean()\n        elif self.reduction == \"sum\":\n            return loss.sum()\n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:22.792446Z","iopub.execute_input":"2025-08-24T05:18:22.792632Z","iopub.status.idle":"2025-08-24T05:18:22.800413Z","shell.execute_reply.started":"2025-08-24T05:18:22.792618Z","shell.execute_reply":"2025-08-24T05:18:22.799716Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"BATCH_SIZE = 64\nEPOCHS     = 30\nLR         = 0.001\nPATIENCE   = 5\nUSE_FOCAL  = False   \n\ndf = pd.read_csv(path)\ny  = (df['LABEL'] == 1).astype(np.int32).values\nX  = df.drop(columns=['LABEL']).values\n\n\nX = np.nan_to_num(X, nan=np.nanmedian(X))\nmed = np.median(X, axis=1, keepdims=True)\nXc  = X - med\nmad = np.median(np.abs(Xc), axis=1, keepdims=True); mad[mad==0]=1.0\nXr  = Xc / mad\n\nX_train, X_temp, y_train, y_temp = train_test_split(Xr, y, test_size=0.2, random_state=42, stratify=y)\nX_val,   X_test, y_val,   y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val   = scaler.transform(X_val)\nX_test  = scaler.transform(X_test)\n\njoblib.dump(scaler, \"scaler.pkl\")\n\ntrain_loader = DataLoader(Exodata(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(Exodata(X_val,   y_val),   batch_size=BATCH_SIZE, shuffle=False)\ntest_loader  = DataLoader(Exodata(X_test,  y_test),  batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:22.801139Z","iopub.execute_input":"2025-08-24T05:18:22.801361Z","iopub.status.idle":"2025-08-24T05:18:27.833510Z","shell.execute_reply.started":"2025-08-24T05:18:22.801339Z","shell.execute_reply":"2025-08-24T05:18:27.832940Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model = CNN(input_length=X_train.shape[1]).to(device)\n\n# pos_weight for imbalance\npos = y_train.sum(); neg = len(y_train) - pos\npos_weight = torch.tensor([neg / (pos + 1e-12)], dtype=torch.float32, device=device)\n\nbce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\ncriterion = FocalLoss() if USE_FOCAL else bce_loss\n\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n\ndef evaluate(model, loader):\n    model.eval()\n    all_prob, all_y = [], []\n    with torch.no_grad():\n        for xb, yb in loader:\n            xb = xb.to(device); yb = yb.to(device)\n            logits = model(xb)\n            prob   = torch.sigmoid(logits).detach().cpu().numpy()\n            all_prob.append(prob); all_y.append(yb.detach().cpu().numpy())\n    prob = np.concatenate(all_prob).ravel()\n    ytrue= np.concatenate(all_y).ravel().astype(int)\n    yhat = (prob >= 0.5).astype(int)\n    return {\n        \"acc\": accuracy_score(ytrue, yhat),\n        \"prec\": precision_score(ytrue, yhat, zero_division=0),\n        \"rec\": recall_score(ytrue, yhat, zero_division=0),\n        \"f1\": f1_score(ytrue, yhat, zero_division=0),\n        \"roc\": roc_auc_score(ytrue, prob),\n        \"pr\":  average_precision_score(ytrue, prob),\n        \"y\": ytrue, \"p\": prob\n    }\n\nbest_pr = -np.inf\nbest_state = None\npat = 0\n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    running = 0.0\n    for xb, yb in train_loader:\n        xb = xb.to(device); yb = yb.to(device)\n        optimizer.zero_grad()\n        logits = model(xb)\n        loss = criterion(logits, yb)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        running += loss.item() * xb.size(0)\n\n    val_metrics = evaluate(model, val_loader)\n    scheduler.step(val_metrics[\"pr\"])\n    print(f\"Epoch {epoch:02d} | loss {running/len(train_loader.dataset):.4f} | \"\n          f\"val PR {val_metrics['pr']:.4f} | ROC {val_metrics['roc']:.4f}\")\n\n    if val_metrics[\"pr\"] > best_pr + 1e-6:\n        best_pr = val_metrics[\"pr\"]; pat = 0\n        best_state = {\"model\": model.state_dict()}\n        torch.save(best_state, \"model.pth\")\n        print(\"> saved best model\")\n    else:\n        pat += 1\n        if pat >= PATIENCE:\n            print(\"Early stopping.\"); break\n\nif best_state is not None:\n    model.load_state_dict(best_state[\"model\"])\nelse:\n    torch.save({\"model\": model.state_dict()}, \"model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:27.834175Z","iopub.execute_input":"2025-08-24T05:18:27.834383Z","iopub.status.idle":"2025-08-24T05:18:49.567650Z","shell.execute_reply.started":"2025-08-24T05:18:27.834367Z","shell.execute_reply":"2025-08-24T05:18:49.566834Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | loss 0.0099 | val PR 0.9983 | ROC 0.7773\n> saved best model\nEpoch 02 | loss 0.0090 | val PR 0.9999 | ROC 0.9908\n> saved best model\nEpoch 03 | loss 0.0084 | val PR 0.9995 | ROC 0.9157\nEpoch 04 | loss 0.0083 | val PR 0.9999 | ROC 0.9908\nEpoch 05 | loss 0.0076 | val PR 0.9999 | ROC 0.9888\nEpoch 06 | loss 0.0070 | val PR 0.9999 | ROC 0.9914\n> saved best model\nEpoch 07 | loss 0.0073 | val PR 1.0000 | ROC 0.9928\n> saved best model\nEpoch 08 | loss 0.0065 | val PR 0.9993 | ROC 0.8972\nEpoch 09 | loss 0.0062 | val PR 0.9998 | ROC 0.9657\nEpoch 10 | loss 0.0058 | val PR 0.9991 | ROC 0.8722\nEpoch 11 | loss 0.0052 | val PR 1.0000 | ROC 0.9934\n> saved best model\nEpoch 12 | loss 0.0062 | val PR 0.9997 | ROC 0.9585\nEpoch 13 | loss 0.0046 | val PR 0.9995 | ROC 0.9302\nEpoch 14 | loss 0.0043 | val PR 0.9997 | ROC 0.9480\nEpoch 15 | loss 0.0045 | val PR 0.9997 | ROC 0.9572\nEpoch 16 | loss 0.0041 | val PR 0.9997 | ROC 0.9578\nEarly stopping.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"class ModelWithTemperature(nn.Module):\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n        self.temperature = nn.Parameter(torch.ones(1))\n    def forward(self, x):\n        return self.model(x) / self.temperature\n    def set_temperature(self, loader):\n        self.to(device)\n        crit = nn.BCEWithLogitsLoss()\n        logits_list, labels_list = [], []\n        self.eval()\n        with torch.no_grad():\n            for xb, yb in loader:\n                xb = xb.to(device)\n                logits_list.append(self.model(xb).detach().cpu())\n                labels_list.append(yb)\n        logits = torch.cat(logits_list).squeeze()\n        labels = torch.cat(labels_list).to(torch.float32).squeeze()\n        T = torch.ones(1, requires_grad=True, device=device)\n        opt = torch.optim.LBFGS([T], lr=0.01, max_iter=50)\n        def closure():\n            opt.zero_grad()\n            loss = crit(logits.to(device)/T, labels.to(device))\n            loss.backward(); return loss\n        opt.step(closure)\n        self.temperature.data = T.data\n        return float(self.temperature.item())\n\nmodel_ts = ModelWithTemperature(model)\nT = model_ts.set_temperature(val_loader)\nnp.save(\"temperature.npy\", np.array([T]))\nprint(f\"Calibrated temperature: {T:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:49.569393Z","iopub.execute_input":"2025-08-24T05:18:49.569610Z","iopub.status.idle":"2025-08-24T05:18:49.814420Z","shell.execute_reply.started":"2025-08-24T05:18:49.569593Z","shell.execute_reply":"2025-08-24T05:18:49.813831Z"}},"outputs":[{"name":"stdout","text":"Calibrated temperature: 0.9363\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"@torch.no_grad()\ndef predict_with_temp(model_with_temp, loader):\n    model_with_temp.eval()\n    probs, ys = [], []\n    for xb, yb in loader:\n        xb = xb.to(device)\n        logits = model_with_temp(xb)\n        probs.append(torch.sigmoid(logits).cpu().numpy())\n        ys.append(yb.numpy())\n    return np.concatenate(ys).ravel().astype(int), np.concatenate(probs).ravel()\n\ny_true, y_prob = predict_with_temp(model_ts, test_loader)\n\ndef print_metrics(y_true, y_prob, thr=0.5):\n    y_hat = (y_prob >= thr).astype(int)\n    m = dict(\n        acc = accuracy_score(y_true, y_hat),\n        prec= precision_score(y_true, y_hat, zero_division=0),\n        rec = recall_score(y_true, y_hat, zero_division=0),\n        f1  = f1_score(y_true, y_hat, zero_division=0),\n        roc = roc_auc_score(y_true, y_prob),\n        pr  = average_precision_score(y_true, y_prob),\n    )\n    print({k: round(v,4) for k,v in m.items()}); return m\n\nprint(\"Test (calibrated) metrics:\")\n_ = print_metrics(y_true, y_prob, 0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:49.815102Z","iopub.execute_input":"2025-08-24T05:18:49.815360Z","iopub.status.idle":"2025-08-24T05:18:49.879041Z","shell.execute_reply.started":"2025-08-24T05:18:49.815342Z","shell.execute_reply":"2025-08-24T05:18:49.878468Z"}},"outputs":[{"name":"stdout","text":"Test (calibrated) metrics:\n{'acc': 0.8546, 'prec': 1.0, 'rec': 0.8535, 'f1': 0.9209, 'roc': 0.9748, 'pr': 0.9998}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def saliency_map(model_core, x_np):\n    model_core.eval()\n    x = torch.tensor(x_np.astype(np.float32)).unsqueeze(0).unsqueeze(0).to(device)\n    x.requires_grad_()\n    logits = model_core(x)\n    prob = torch.sigmoid(logits)\n    prob.backward()\n    sal = x.grad.detach().cpu().squeeze().numpy()\n    return np.abs(sal)\n\nK = min(3, len(X_test))\nsals = [saliency_map(model_ts.model, X_test[i]) for i in range(K)]\nnp.save(\"saliency_examples.npy\", np.stack(sals, axis=0))\nprint(\"Saved saliency_examples.npy\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T05:18:49.879697Z","iopub.execute_input":"2025-08-24T05:18:49.879944Z","iopub.status.idle":"2025-08-24T05:18:49.894399Z","shell.execute_reply.started":"2025-08-24T05:18:49.879927Z","shell.execute_reply":"2025-08-24T05:18:49.893606Z"}},"outputs":[{"name":"stdout","text":"Saved saliency_examples.npy\n","output_type":"stream"}],"execution_count":28}]}